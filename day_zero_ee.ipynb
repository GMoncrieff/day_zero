{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The impact of the day zero drought on vegetation on the Western Cape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To run this analysis you need access to google earth engine. If you do not have access please sign up for a free account [here](https://signup.earthengine.google.com/])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import uuid\n",
    "import shutil\n",
    "from shutil import unpack_archive\n",
    "import ee\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import rtree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import subprocess, glob\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "#helper functions for usinng gee\n",
    "from gee_modis_clean import getQABits, updateMultipleMask\n",
    "from gee_linear_model import addDependents, addHarmonics, constructBandNames, predict_coeffs, diff_predict\n",
    "from gee_folium import add_ee_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data\n",
    "url = 'https://storage.googleapis.com/day_zero/eg.zip'\n",
    "filename = wget.download(url)\n",
    "unpack_archive(filename)\n",
    "os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate Earth Engine \n",
    "#NB!!! right click and open this link in a new tab\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Earth Engine module.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if earth engine is working by printing metadata for a DEM dataset.\n",
    "print(ee.Image('USGS/SRTMGL1_003').getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data and clip to regions of interest\n",
    "We select 3 biomes - renosterveld, fynbos, and forest- and 2 agricultural land uses - irrigated vineyards and rainfed grains.  \n",
    "Biomes are masked with layers of naturla vegetation remnants and protected areas. \n",
    "We then extract these land uses in three regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vegmap2018\n",
    "#http://bgis.sanbi.org/SpatialDataset/Detail/1674\n",
    "vegmap = gpd.read_file('data/input/vegmap2018/vegmap2018_wc.shp')\n",
    "\n",
    "#wc protected areas\n",
    "#http://bgis.sanbi.org/SpatialDataset/Detail/649\n",
    "wcpa = gpd.read_file('data/input/WCBSP_PA_2017/BSP_PA_2017.shp')\n",
    "wcpa= wcpa[['Name','geometry']]\n",
    "\n",
    "#wc natural\n",
    "#from CapeNature. email: Therese Forsyth <tforsyth@capenature.co.za>\n",
    "remnants = gpd.read_file('data/input/remnants/natrem.shp')\n",
    "remnants = remnants[['OBJECTID','Condition','geometry']]\n",
    "\n",
    "#wc crop types\n",
    "#from WC department of Agricultre. email: FC Basson <FCBasson@elsenburg.com>\n",
    "crops = gpd.read_file('data/input/wc_crops_2013/Crop_Census_2013.shp')\n",
    "crops = crops[['FIELD_ID','CROPS','CR_SUM','DRY_IRR','geometry']]\n",
    "\n",
    "#regions\n",
    "#manually created regions of interest\n",
    "regions = gpd.read_file('data/input/regions/regions.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter BIOREGION_\n",
    "bregions = ['Northwest Fynbos Bioregion','Southern Fynbos Bioregion',\\\n",
    "            'Southwest Fynbos Bioregion','West Coast Renosterveld Bioregion',\\\n",
    "            'East Coast Renosterveld Bioregion','Zonal & Intrazonal Forests',\\\n",
    "           'Azonal Forests']\n",
    "vegmap = vegmap[vegmap['BIOREGION_'].isin(bregions)]\n",
    "\n",
    "#recode as biomes\n",
    "dict = {'Northwest Fynbos Bioregion' : 'Fy', 'Southern Fynbos Bioregion' : 'Fy', \\\n",
    "        'Southwest Fynbos Bioregion' : 'Fy', \\\n",
    "        'West Coast Renosterveld Bioregion' : 'R','East Coast Renosterveld Bioregion' : 'R',\\\n",
    "        'Zonal & Intrazonal Forests' : 'Fo', 'Azonal Forests' : 'Fo'} \n",
    "vegmap['biome']= vegmap['BIOREGION_'].map(dict) \n",
    "\n",
    "vegmap = vegmap[['OBJECTID','BIOREGION_','Name_18', 'biome','geometry']]\n",
    "\n",
    "#filter remnants\n",
    "remnants = remnants[remnants['Condition']=='Natural']\n",
    "\n",
    "#grapes\n",
    "grapes = crops[(crops['CR_SUM']=='Grapes') & (crops['DRY_IRR']=='Irrigated')] \n",
    "grapes['biome']=\"V\"\n",
    "#wheat\n",
    "wheat = crops[(crops['CR_SUM']=='Grains') & (crops['DRY_IRR']=='Dry land')]\n",
    "wheat['biome']=\"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reproject\n",
    "vegmap = vegmap.to_crs({'init': 'epsg:4326'})\n",
    "remnants = remnants.to_crs({'init': 'epsg:4326'})\n",
    "regions = regions.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_r = gpd.overlay(wcpa, regions, how='intersection')\n",
    "veg_r = gpd.overlay(remnants,veg_r, how='intersection')\n",
    "veg_r = gpd.overlay(vegmap,veg_r, how='intersection')\n",
    "grape_r = gpd.overlay(grapes, regions, how='intersection')\n",
    "wheat_r = gpd.overlay(wheat, regions, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veg_r.to_file('veg_r.shp')\n",
    "#grape_r.to_file('gr.shp')\n",
    "#wheat_r.to_file('wr.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_r = veg_r[['OBJECTID_1','Name_18','biome','rname','geometry']]\n",
    "grape_r = grape_r[['FIELD_ID','CROPS','biome','rname','geometry']]\n",
    "wheat_r = wheat_r[['FIELD_ID','CROPS','biome','rname','geometry']]\n",
    "\n",
    "dict= {\"FIELD_ID\":\"OBJECTID_1\", \"CROPS\": \"Name_18\", \"biome\":\"biome\", \"rname\":\"rname\", \"geometry\":\"geometry\"}\n",
    "grape_r = grape_r.rename(columns=dict)\n",
    "wheat_r = wheat_r.rename(columns=dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r = veg_r.append(grape_r).append(wheat_r)\n",
    "all_r['code'] = all_r['rname'] + '__' + all_r['biome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dissolve\n",
    "all_r = all_r.dissolve(by='code', aggfunc='first')\n",
    "all_r['code'] = all_r.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to utm so unit is meters\n",
    "all_r_utm =all_r.to_crs({'init': 'epsg:32734'})\n",
    "#buffer by 125 meters\n",
    "all_r_utm['geometry'] = all_r_utm.geometry.buffer(-125)\n",
    "#polyarea\n",
    "all_r_utm[\"area\"] = all_r_utm['geometry'].area\n",
    "#remove empty\n",
    "all_r_utm = all_r_utm[all_r_utm[\"area\"]>0]\n",
    "#return to WGS\n",
    "all_r =all_r_utm.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codedic = {'cape_metropole__Fo': 1,\\\n",
    "'cape_metropole__Fy': 2,\\\n",
    "'cape_metropole__G': 3,\\\n",
    "'cape_metropole__R':4,\\\n",
    "'cape_metropole__V':5,\\\n",
    "'jonaskop__Fo':6,\\\n",
    "'jonaskop__Fy': 7,\\\n",
    "'jonaskop__G': 8,\\\n",
    "'jonaskop__R': 9,\\\n",
    "'jonaskop__V': 10,\\\n",
    "'west_coast__Fo': 11,\\\n",
    "'west_coast__Fy': 12,\\\n",
    "'west_coast__G': 13,\\\n",
    "'west_coast__R': 14,\\\n",
    "'west_coast__V': 15,\\\n",
    "'western_overberg__Fo': 16,\\\n",
    "'western_overberg__Fy': 17,\\\n",
    "'western_overberg__G': 18,\\\n",
    "'western_overberg__V': 19,\\\n",
    "'western_overberg__R': 20}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codedic2 = {'cape_metropole__Forest': 1,\\\n",
    "'cape_metropole__Fynbos': 2,\\\n",
    "'cape_metropole__Grains': 3,\\\n",
    "'cape_metropole__Rensoterveld':4,\\\n",
    "'cape_metropole__V':5,\\\n",
    "'jonaskop__Forest':6,\\\n",
    "'jonaskop__Fynbos': 7,\\\n",
    "'jonaskop__Grains': 8,\\\n",
    "'jonaskop__Rensoterveld': 9,\\\n",
    "'jonaskop__Vineyards': 10,\\\n",
    "'west_coast__Forest': 11,\\\n",
    "'west_coast__Fynbos': 12,\\\n",
    "'west_coast__Grains': 13,\\\n",
    "'west_coast__Rensoterveld': 14,\\\n",
    "'west_coast__Vineyards': 15,\\\n",
    "'western_overberg__Forest': 16,\\\n",
    "'western_overberg__Fynbos': 17,\\\n",
    "'western_overberg__Grains': 18,\\\n",
    "'western_overberg__Vineyards': 19,\\\n",
    "'western_overberg__Rensoterveld': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r['codeint']= all_r['code'].map(codedic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the extracted areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "all_r.plot(column='code',\n",
    "            ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r.to_file('data/output/all_r.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to GEE\n",
    "sure we could do thisusing a bunch of command line tools and google cloud storage, but it is easier for you to ust download `all_r.shp` and upload it manually to GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Earth engine bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in polygons and rasterize\n",
    "area = ee.FeatureCollection(\"users/glennwithtwons/all_r\")\n",
    "\n",
    "areaRas = area \\\n",
    "  .filter(ee.Filter.notNull(['codeint'])) \\\n",
    "  .reduceToImage(properties = ['codeint'],reducer = ee.Reducer.first()) \\\n",
    "  .rename(['codeint'])\n",
    "\n",
    "#create mask\n",
    "areaMask = area \\\n",
    "  .filter(ee.Filter.notNull(['codeint'])) \\\n",
    "  .map(lambda feature: feature.set('flag', ee.Number(1))) \\\n",
    "  .reduceToImage(['flag'],ee.Reducer.first()) \\\n",
    "  .rename(['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of cycles per year to model.\n",
    "harmonics = 1\n",
    "index= 'NDVI'\n",
    "\n",
    "# Make a list of harmonic frequencies to model.\n",
    "# These also serve as band name suffixes.\n",
    "harmonicFrequencies = ee.List.sequence(1, harmonics)\n",
    "harmonicFrequencies_st = list(range(1,harmonics+1))\n",
    "\n",
    "# Construct lists of names for the harmonic terms.\n",
    "cosNames = constructBandNames('cos_', harmonicFrequencies_st)\n",
    "sinNames = constructBandNames('sin_', harmonicFrequencies_st)\n",
    "\n",
    "# Independent variables = intercept, time, and kernel mean\n",
    "independents = ee.List(['constant','t']) \\\n",
    "  .cat(cosNames).cat(sinNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "col_tr = ee.ImageCollection('MODIS/006/MYD13Q1')\\\n",
    "  .merge(ee.ImageCollection('MODIS/006/MOD13Q1'))\\\n",
    "  .filterBounds(area)\\\n",
    "  .filterDate('2000-01-01', '2014-12-31')\\\n",
    "  .map(updateMultipleMask(index,areaMask)) \\\n",
    "  .select(index)\\\n",
    "  .map(addDependents) \\\n",
    "  .map(addHarmonics(harmonicFrequencies,cosNames,sinNames))\n",
    "\n",
    "col_val = ee.ImageCollection('MODIS/006/MYD13Q1')\\\n",
    "  .merge(ee.ImageCollection('MODIS/006/MOD13Q1'))\\\n",
    "  .filterBounds(area)\\\n",
    "  .filterDate('2001-01-01', '2019-12-31')\\\n",
    "  .map(updateMultipleMask(index,areaMask)) \\\n",
    "  .select(index)\\\n",
    "  .map(addDependents) \\\n",
    "  .map(addHarmonics(harmonicFrequencies,cosNames,sinNames))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependent variable we are modeling.\n",
    "dependents = ee.List([index])\n",
    "\n",
    "#fit the regression\n",
    "# The output of the regression reduction is a 4x1 array image.\n",
    "harmonicTrend_tr = col_tr.select(independents.cat(dependents)).reduce(ee.Reducer.robustLinearRegression(independents.length(), 1))\n",
    "# Turn the array image into a multi-band image of coefficients.\n",
    "hTC = harmonicTrend_tr.select('coefficients').arrayProject([0]).arrayFlatten([independents])\n",
    "#RMSE\n",
    "hResid = harmonicTrend_tr.select('residuals').arrayFlatten([dependents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions on data using fitted model\n",
    "#then transform imgCol to multiband img\n",
    "col_val_fit = col_val \\\n",
    "      .map(predict_coeffs(independents,hTC))\\\n",
    "      .map(diff_predict(index))\\\n",
    "      .sort('system:time_start', False) \\\n",
    "      .map(lambda image: image.select(['fitted'])) \\\n",
    "      .toBands() \\\n",
    "      .toFloat()\n",
    "\n",
    "col_val_raw = col_val \\\n",
    "      .sort('system:time_start', False) \\\n",
    "      .map(lambda image: image.select([index])) \\\n",
    "      .toBands() \\\n",
    "      .toFloat()\n",
    "\n",
    "col_exp = areaRas \\\n",
    "  .toFloat() \\\n",
    "  .addBands(col_val_fit)\\\n",
    "  .addBands(col_val_raw)\\\n",
    "  .addBands(ee.Image.pixelLonLat())\\\n",
    "  .toFloat() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates and names of bands\n",
    "ndname = col_exp.getInfo()\n",
    "ndvi_id = pd.DataFrame(ndname.get('bands'))['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export task\n",
    "task = ee.batch.Export.image.toDrive(image=col_exp,\n",
    "                                     region=area.geometry(),\n",
    "                                     description='ndras_all',\n",
    "                                     scale=250)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check on task\n",
    "task.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize EE output\n",
    "This might take a while so beware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = col_val_fit.select(['1_2019_11_09_fitted'])\n",
    "\n",
    "# Set visualization parameters.\n",
    "vis_params = {\n",
    "  'min': 0,\n",
    "  'max': 8000,\n",
    "  'palette': ['FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901',\n",
    "    '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01',\n",
    "    '012E01', '011D01', '011301']}\n",
    "\n",
    "# Add EE drawing method to folium.\n",
    "folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "# Create a folium map object.\n",
    "my_map = folium.Map(location=[-33.98,18.39], zoom_start=10)\n",
    "\n",
    "# Add the ndvi to the map object.\n",
    "my_map.add_ee_layer(im, vis_params, 'map')\n",
    "#my_map.add_ee_layer(area, vis_params, 'map')\n",
    "# Add a layer control panel to the map.\n",
    "my_map.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read exported data from GDrive\n",
    "Again I could link my gdrive to copy over the file, but that is a waste of time. It is quicker tpp manually download and upload it here to the `output` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in ndvi data and convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to merge files togehter as ee can output big rasters as multiple files\n",
    "dirpath = r\"data/output/ndras\"\n",
    "search_criteria = \"ndras*.tif\"\n",
    "q = os.path.join(dirpath, search_criteria)\n",
    "nd_files = glob.glob(q)\n",
    "nd_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert raster to df\n",
    "def r2df(filename):\n",
    "    with rio.open(filename) as src:\n",
    "    #read image\n",
    "        image= src.read()\n",
    "        # transform image\n",
    "        bands,rows,cols = np.shape(image)\n",
    "        image1 = image.reshape (bands,rows*cols)\n",
    "        #export  to df\n",
    "        nddf = pd.DataFrame(image1.transpose())\n",
    "        nddf = nddf[pd.notnull(nddf[0])]\n",
    "    return nddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply to all rasters\n",
    "nddf = pd.concat([x for x in map(r2df, nd_files)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column and subsample\n",
    "nddf.columns = ndvi_id \n",
    "ndsamp = nddf.sample(frac=1).groupby('codeint').head(10)\n",
    "\n",
    "#reshape df to long\n",
    "ndsamp = pd.melt(ndsamp, id_vars=['longitude','latitude','codeint'],var_name = 'dt',value_name='vi')\n",
    "\n",
    "#create new colun to id each row \n",
    "ndsamp['sat'] = ndsamp['dt'].str.slice(start=0,stop=1)\n",
    "ndsamp['nd'] = ndsamp['dt'].str.slice(start=13)\n",
    "#format dates\n",
    "ndsamp['date'] = ndsamp['dt'].str.slice(start=2,stop=12)\n",
    "ndsamp['date'] = pd.to_datetime(ndsamp['date'],format='%Y_%m_%d')\n",
    "# rescale ndvi\n",
    "ndsamp['vi'] = ndsamp['vi']/10000\n",
    "#create test and val set\n",
    "ndsamp['grp'] = ndsamp['date']>pd.to_datetime('2014-12-31')\n",
    "#lat lng as string\n",
    "ndsamp['px'] = ndsamp['longitude'].astype(str) +  ndsamp['latitude'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot and add a col for ndvi diff\n",
    "ndsamp = pd.pivot_table(ndsamp,index=['longitude','latitude','codeint','date','grp','px'],columns='nd',values='vi')\n",
    "ndsamp = ndsamp.reset_index()\n",
    "ndsamp['residual'] = ndsamp['NDVI']-testn['fitted']\n",
    "ndsamp = pd.melt(ndsamp, id_vars=['longitude','latitude','codeint','date','grp','px'],var_name = 'nd',value_name='vi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate means\n",
    "ndav = ndsamp.groupby(['codeint','nd','date','grp']).agg(vimean=('vi', 'mean')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot woth alt air, we need to combine to average data and the obs data\n",
    "ndav['px'] = 'average'\n",
    "ndav['vi'] = np.NaN\n",
    "\n",
    "ndplot = ndsamp[ndsamp['nd']!='fitted']\n",
    "ndplot['vimean'] = np.NaN\n",
    "ndplot=ndplot[ndav.columns]\n",
    "ndplot['fgp'] = \"raw\"\n",
    "ndavplot = ndav\n",
    "ndavplot['fgp'] = 'av'\n",
    "\n",
    "ndall = ndplot.append(ndavplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {v: k for k, v in codedic2.items()}\n",
    "ndall['codeint'] = ndall['codeint'].fillna(0).astype(int).map(new_dict)\n",
    "#.map(codedic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up labesl\n",
    "ndall['nd'] = ndall['nd'].str.replace('NDVI', 'observed')\n",
    "ndall['grp'] = np.where(ndall['grp'], 'prediction', 'calibration')\n",
    "\n",
    "#create two dfs\n",
    "#one for plotting obs and fitted\n",
    "ndobs = ndall[ndall['nd']!='residual']\n",
    "\n",
    "#onr for plotting anomalies\n",
    "ndfit = ndall[ndall['nd']=='residual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "#alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = alt.Chart(width=200,height=200).mark_line(\n",
    "    opacity=0.3,\n",
    "    size=0.2\n",
    ").encode(\n",
    "    x=alt.X('date',title='date'),\n",
    "    y=alt.X('vi',title='NDVI'),\n",
    "    color='grp',\n",
    "    detail ='px'\n",
    ")\n",
    "group=alt.Chart(width=200,height=200).mark_line(\n",
    "    size=2\n",
    ").encode(\n",
    "    x=alt.X('date',title='date'),\n",
    "    y=alt.X('vimean',title='NDVI'),\n",
    "    color='nd',\n",
    "    detail ='px'\n",
    ")\n",
    "\n",
    "chart_ndvi =alt.layer(obs,group).facet(\"codeint\",columns=3,data=ndobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = alt.Chart(width=200,height=200).mark_line(\n",
    "    opacity=0.3,\n",
    "    size=0.2\n",
    ").encode(\n",
    "    x=alt.X('date',title='date'),\n",
    "    y=alt.X('vi',title='residual'),\n",
    "    color='grp',\n",
    "    detail ='px'\n",
    ")\n",
    "group=alt.Chart(width=200,height=200).mark_line(\n",
    "    size=2\n",
    ").encode(\n",
    "    x=alt.X('date',title='date'),\n",
    "    y=alt.X('vimean',title='residual'),\n",
    "    detail ='px'\n",
    ")\n",
    "\n",
    "#alt.layer(group,obs)\n",
    "chart_fit =alt.layer(obs,group).facet(\"codeint\",columns=3,data=ndfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dayzero]",
   "language": "python",
   "name": "conda-env-dayzero-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
